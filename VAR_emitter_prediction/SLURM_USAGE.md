# VAR Emitterè®­ç»ƒ SLURMä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•åœ¨SLURMé›†ç¾¤ä¸Šæäº¤å’Œç›‘æ§VAR Emitteré¢„æµ‹æ¨¡å‹çš„è®­ç»ƒä»»åŠ¡ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

- `submit_var_training.slurm` - SLURMä½œä¸šè„šæœ¬
- `submit_training.sh` - è®­ç»ƒæäº¤è„šæœ¬
- `check_training_status.sh` - çŠ¶æ€æ£€æŸ¥è„šæœ¬

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æäº¤è®­ç»ƒä½œä¸š

```bash
cd /home/guest/Others/DECODE_rewrite/VAR_emitter_prediction
./submit_training.sh
```

### 2. æ£€æŸ¥ä½œä¸šçŠ¶æ€

```bash
# æŸ¥çœ‹æ‰€æœ‰ä½œä¸š
./check_training_status.sh

# æŸ¥çœ‹ç‰¹å®šä½œä¸šè¯¦æƒ…
./check_training_status.sh <JOB_ID>
```

## ğŸ“Š SLURMä½œä¸šé…ç½®

### èµ„æºé…ç½®
- **ä½œä¸šåç§°**: `var_emitter_training`
- **è¿è¡Œæ—¶é—´**: 24å°æ—¶
- **èŠ‚ç‚¹æ•°é‡**: 1
- **CPUæ ¸å¿ƒ**: 8
- **å†…å­˜**: 64GB
- **GPU**: 1å¼ 
- **åˆ†åŒº**: gpu

### è¾“å‡ºæ–‡ä»¶
- æ ‡å‡†è¾“å‡º: `logs/var_training_<JOB_ID>.out`
- é”™è¯¯è¾“å‡º: `logs/var_training_<JOB_ID>.err`
- è®­ç»ƒæ—¥å¿—: `logs/training_<JOB_ID>.log`

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### ä¿®æ”¹èµ„æºéœ€æ±‚

ç¼–è¾‘ `submit_var_training.slurm` æ–‡ä»¶ä¸­çš„SBATCHå‚æ•°ï¼š

```bash
#SBATCH --time=24:00:00        # è¿è¡Œæ—¶é—´
#SBATCH --cpus-per-task=8      # CPUæ ¸å¿ƒæ•°
#SBATCH --mem=64G              # å†…å­˜å¤§å°
#SBATCH --gres=gpu:1           # GPUæ•°é‡
#SBATCH --partition=gpu        # åˆ†åŒºåç§°
```

### ä¿®æ”¹è®­ç»ƒå‚æ•°

ç¼–è¾‘ `configs/config_true_var.json` é…ç½®æ–‡ä»¶ï¼š

```json
{
  "batch_size": 2,
  "learning_rate": 1e-4,
  "num_epochs": 100,
  "input_resolution": 160
}
```

## ğŸ“‹ ç›‘æ§å‘½ä»¤

### åŸºæœ¬SLURMå‘½ä»¤

```bash
# æŸ¥çœ‹ä½œä¸šé˜Ÿåˆ—
squeue -u $USER

# æŸ¥çœ‹ç‰¹å®šä½œä¸š
squeue -j <JOB_ID>

# å–æ¶ˆä½œä¸š
scancel <JOB_ID>

# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€
sinfo

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
scontrol show job <JOB_ID>
```

### æ—¥å¿—ç›‘æ§

```bash
# å®æ—¶æŸ¥çœ‹è¾“å‡ºæ—¥å¿—
tail -f logs/var_training_<JOB_ID>.out

# å®æ—¶æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/var_training_<JOB_ID>.err

# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training_<JOB_ID>.log
```

### TensorBoardç›‘æ§

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir=logs/tensorboard --port=6006

# SSHç«¯å£è½¬å‘ï¼ˆåœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œï¼‰
ssh -L 6006:localhost:6006 user@server

# æµè§ˆå™¨è®¿é—®
http://localhost:6006
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä½œä¸šæäº¤å¤±è´¥**
   ```bash
   # æ£€æŸ¥SLURMçŠ¶æ€
   sinfo
   
   # æ£€æŸ¥èµ„æºé…é¢
   sshare -u $USER
   ```

2. **GPUä¸å¯ç”¨**
   ```bash
   # æ£€æŸ¥GPUèŠ‚ç‚¹
   sinfo -p gpu
   
   # ä¿®æ”¹åˆ†åŒºä¸ºCPU
   # åœ¨submit_var_training.slurmä¸­æ³¨é‡Šæ‰GPUç›¸å…³è¡Œ
   ```

3. **å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   # ç¼–è¾‘configs/config_true_var.jsonä¸­çš„batch_size
   ```

4. **è®­ç»ƒä¸­æ–­**
   ```bash
   # æ£€æŸ¥æ£€æŸ¥ç‚¹
   ls -la outputs/
   
   # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
   # è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤
   ```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
grep -i "epoch" logs/training_<JOB_ID>.log

# æŸ¥çœ‹æŸå¤±å˜åŒ–
grep -i "loss" logs/training_<JOB_ID>.log

# æŸ¥çœ‹Count Lossæ•ˆæœ
grep -i "count" logs/training_<JOB_ID>.log

# æŸ¥çœ‹é”™è¯¯ä¿¡æ¯
grep -i "error\|exception" logs/var_training_<JOB_ID>.err
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§æŒ‡æ ‡

### ä¸»è¦æŸå¤±å‡½æ•°
- `Total loss` - æ€»æŸå¤±
- `scale_0_count` - 10x10åˆ†è¾¨ç‡è®¡æ•°æŸå¤±
- `scale_1_count` - 20x20åˆ†è¾¨ç‡è®¡æ•°æŸå¤±
- `scale_2_count` - 40x40åˆ†è¾¨ç‡è®¡æ•°æŸå¤±
- `scale_3_count` - 80x80åˆ†è¾¨ç‡è®¡æ•°æŸå¤±
- `Count loss` - æ€»è®¡æ•°æŸå¤±

### æ€§èƒ½æŒ‡æ ‡
- `Prob sum` - æ¦‚ç‡å›¾æ€»å’Œï¼ˆåº”æ¥è¿‘çœŸå®emitteræ•°é‡ï¼‰
- è®­ç»ƒæ—¶é—´æ¯epoch
- GPUåˆ©ç”¨ç‡
- å†…å­˜ä½¿ç”¨æƒ…å†µ

## ğŸ’¡ æœ€ä½³å®è·µ

1. **èµ„æºè§„åˆ’**
   - æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´å†…å­˜éœ€æ±‚
   - é•¿æ—¶é—´è®­ç»ƒå»ºè®®ä½¿ç”¨æ£€æŸ¥ç‚¹ä¿å­˜
   - ç›‘æ§GPUåˆ©ç”¨ç‡ä¼˜åŒ–æ‰¹æ¬¡å¤§å°

2. **æ—¥å¿—ç®¡ç†**
   - å®šæœŸæ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
   - ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
   - ä¿å­˜é‡è¦çš„è®­ç»ƒé…ç½®å’Œç»“æœ

3. **æ•…éšœæ¢å¤**
   - å¯ç”¨è‡ªåŠ¨æ£€æŸ¥ç‚¹ä¿å­˜
   - è®¾ç½®åˆç†çš„é‡å¯ç­–ç•¥
   - ç›‘æ§ç£ç›˜ç©ºé—´ä½¿ç”¨

## ğŸ“ æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. SLURMé›†ç¾¤çŠ¶æ€
2. é…ç½®æ–‡ä»¶æ ¼å¼
3. æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®
4. ä¾èµ–åŒ…æ˜¯å¦å®‰è£…å®Œæ•´

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ `docs/README_SLURM.md`ã€‚