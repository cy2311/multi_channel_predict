# VAR-based Emitter Prediction

åŸºäºVARï¼ˆVisual AutoRegressiveï¼‰æ¡†æ¶çš„é«˜å¯†åº¦emitteré¢„æµ‹ç³»ç»Ÿï¼Œé€šè¿‡å¤šå°ºåº¦æ¸è¿›å¼é¢„æµ‹æœºåˆ¶è§£å†³ä¼ ç»ŸU-Netç½‘ç»œå°ºå¯¸é™åˆ¶é—®é¢˜ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ å¤šå°ºåº¦æ¸è¿›å¼é¢„æµ‹
- **è¾“å…¥**: 40Ã—40 ä½åˆ†è¾¨ç‡TIFFå›¾åƒ
- **è¾“å‡º**: å¤šä¸ªé«˜åˆ†è¾¨ç‡é¢„æµ‹å›¾ï¼ˆ80Ã—80, 160Ã—160, 320Ã—320ç­‰ï¼‰
- **æœºåˆ¶**: å€Ÿé‰´VARçš„ä¸‹ä¸€å°ºåº¦é¢„æµ‹ï¼Œå®ç°è¶…åˆ†è¾¨ç‡emitterå®šä½

### ğŸ§  VAR-inspiredæ¶æ„
- **MultiScaleVQVAE**: å¤šå°ºåº¦çŸ¢é‡é‡åŒ–è‡ªç¼–ç å™¨
- **ProgressiveEmitterTransformer**: æ¸è¿›å¼Transformeré¢„æµ‹å™¨
- **VectorQuantizer**: ç¦»æ•£åŒ–emitterè¡¨ç¤º

### ğŸ“Š ç»“æ„åŒ–æŸå¤±å‡½æ•°
- **CountLoss**: åŸºäºæ³Šæ¾äºŒé¡¹å¼åˆ†å¸ƒçš„è®¡æ•°æŸå¤±
- **LocalizationLoss**: ç²¾ç¡®ä½ç½®é¢„æµ‹æŸå¤±
- **ReconstructionLoss**: é‡å»ºè´¨é‡æŸå¤±
- **UncertaintyLoss**: é¢„æµ‹ä¸ç¡®å®šæ€§æŸå¤±
- **å¤šå°ºåº¦æƒé‡**: ä¸åŒåˆ†è¾¨ç‡çš„è‡ªé€‚åº”æƒé‡

## é¡¹ç›®ç»“æ„

```
VAR_emitter_prediction/
â”œâ”€â”€ __init__.py                 # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ var_emitter_model.py        # æ ¸å¿ƒæ¨¡å‹æ¶æ„
â”œâ”€â”€ var_emitter_loss.py         # æŸå¤±å‡½æ•°å®šä¹‰
â”œâ”€â”€ var_dataset.py              # æ•°æ®åŠ è½½å’Œå¤„ç†
â”œâ”€â”€ train_var_emitter.py        # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py                # æ¨ç†è„šæœ¬
â”œâ”€â”€ config.json                 # é…ç½®æ–‡ä»¶æ¨¡æ¿
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install torch torchvision torchaudio
pip install h5py tifffile pillow matplotlib seaborn
pip install scipy tensorboard tqdm
```

### 2. æ•°æ®å‡†å¤‡

å‡†å¤‡ä¸¤å¥—æ•°æ®ï¼š
- **è®­ç»ƒæ•°æ®**: é«˜åˆ†è¾¨ç‡TIFFæ–‡ä»¶ï¼ˆå¦‚320Ã—320ï¼‰+ å¯¹åº”çš„emitter H5æ–‡ä»¶
- **æ¨ç†æ•°æ®**: 40Ã—40åˆ†è¾¨ç‡TIFFæ–‡ä»¶

æ•°æ®ç›®å½•ç»“æ„ï¼š
```
data/
â”œâ”€â”€ train_tiff/          # é«˜åˆ†è¾¨ç‡è®­ç»ƒTIFF
â”‚   â”œâ”€â”€ frame_001.tif
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train_emitters/      # å¯¹åº”çš„emitter H5æ–‡ä»¶
â”‚   â”œâ”€â”€ frame_001.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ inference_tiff/      # 40Ã—40æ¨ç†TIFF
    â”œâ”€â”€ test_001.tif
    â””â”€â”€ ...
```

### 3. é…ç½®è®¾ç½®

ç¼–è¾‘ `config.json` æ–‡ä»¶ï¼š

```json
{
  "model": {
    "input_size": [40, 40],           # æ¨ç†è¾“å…¥å°ºå¯¸
    "target_sizes": [[80, 80], [160, 160], [320, 320]],  # è®­ç»ƒç›®æ ‡å°ºå¯¸
    "base_channels": 64,
    "embed_dim": 512,
    "num_heads": 8,
    "num_layers": 6
  },
  "training": {
    "num_epochs": 100,
    "batch_size": 8,
    "progressive": true,              # å¯ç”¨æ¸è¿›å¼è®­ç»ƒ
    "warmup_epochs": 20
  },
  "loss": {
    "count_weight": 1.0,              # è®¡æ•°æŸå¤±æƒé‡
    "loc_weight": 1.0,                # å®šä½æŸå¤±æƒé‡
    "recon_weight": 0.1,              # é‡å»ºæŸå¤±æƒé‡
    "uncertainty_weight": 0.5,        # ä¸ç¡®å®šæ€§æŸå¤±æƒé‡
    "scale_weights": [0.5, 0.8, 1.0]  # å¤šå°ºåº¦æƒé‡
  }
}
```

### 4. è®­ç»ƒæ¨¡å‹

```bash
python train_var_emitter.py \
    --config config.json \
    --tiff_dir data/train_tiff \
    --emitter_dir data/train_emitters \
    --output_dir outputs/training \
    --device cuda
```

è®­ç»ƒç‰¹æ€§ï¼š
- **æ¸è¿›å¼è®­ç»ƒ**: ä»ä½åˆ†è¾¨ç‡é€æ­¥å¢åŠ åˆ°é«˜åˆ†è¾¨ç‡
- **æ··åˆç²¾åº¦**: è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒåŠ é€Ÿ
- **Tensorboard**: å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- **æ£€æŸ¥ç‚¹**: è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹

### 5. æ¨¡å‹æ¨ç†

```bash
python inference.py \
    --checkpoint outputs/training/best_model.pth \
    --config outputs/training/config.json \
    --input_dir data/inference_tiff \
    --output_dir outputs/inference \
    --batch_size 8
```

æ¨ç†è¾“å‡ºï¼š
- **å¤šå°ºåº¦æ¦‚ç‡å›¾**: ä¸åŒåˆ†è¾¨ç‡çš„emitteræ¦‚ç‡
- **ä½ç½®å›¾**: ç²¾ç¡®çš„emitterä½ç½®é¢„æµ‹
- **ä¸ç¡®å®šæ€§å›¾**: é¢„æµ‹ç½®ä¿¡åº¦
- **å¯è§†åŒ–ç»“æœ**: ç›´è§‚çš„é¢„æµ‹ç»“æœå›¾
- **åŸå§‹æ•°æ®**: HDF5æ ¼å¼çš„å®Œæ•´é¢„æµ‹æ•°æ®

## æ ¸å¿ƒç®—æ³•

### å¤šå°ºåº¦æ¸è¿›å¼é¢„æµ‹

1. **ç¼–ç é˜¶æ®µ**: å°†40Ã—40è¾“å…¥ç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤º
2. **é‡åŒ–é˜¶æ®µ**: ä½¿ç”¨VQ-VAEè¿›è¡Œç¦»æ•£åŒ–è¡¨ç¤º
3. **æ¸è¿›å¼è§£ç **: é€æ­¥é¢„æµ‹æ›´é«˜åˆ†è¾¨ç‡çš„emitteråˆ†å¸ƒ
4. **å¤šä»»åŠ¡è¾“å‡º**: åŒæ—¶é¢„æµ‹æ¦‚ç‡ã€ä½ç½®å’Œä¸ç¡®å®šæ€§

### æŸå¤±å‡½æ•°è®¾è®¡

```python
Total_Loss = Î±â‚ Ã— Count_Loss + Î±â‚‚ Ã— Loc_Loss + Î±â‚ƒ Ã— Recon_Loss + Î±â‚„ Ã— Uncertainty_Loss

# å¤šå°ºåº¦åŠ æƒ
Scale_Loss = Î£áµ¢ wáµ¢ Ã— Loss_at_scale_i
```

å…¶ä¸­ï¼š
- **Count_Loss**: åŸºäºæ³Šæ¾äºŒé¡¹å¼åˆ†å¸ƒçš„è®¡æ•°æŸå¤±
- **Loc_Loss**: L2ä½ç½®å›å½’æŸå¤±
- **Recon_Loss**: é‡å»ºè´¨é‡æŸå¤±
- **Uncertainty_Loss**: ä¸ç¡®å®šæ€§æ­£åˆ™åŒ–æŸå¤±

## æŠ€æœ¯ä¼˜åŠ¿

### ğŸ” è¶…åˆ†è¾¨ç‡é¢„æµ‹
- ä»40Ã—40è¾“å…¥é¢„æµ‹320Ã—320è¾“å‡º
- ä¿æŒç‰©ç†å°ºå¯¸ä¸€è‡´æ€§
- åˆ©ç”¨é«˜åˆ†è¾¨ç‡è®­ç»ƒæ•°æ®çš„ç²¾ç»†ä¿¡æ¯

### ğŸ¯ é«˜å¯†åº¦å¤„ç†
- è§£å†³ä¼ ç»ŸU-Netçš„å°ºå¯¸é™åˆ¶
- æ”¯æŒå¯†é›†emitteråœºæ™¯
- æ¸è¿›å¼é¢„æµ‹æé«˜ç²¾åº¦

### ğŸ§  æ™ºèƒ½æ¶æ„
- VAR-inspiredå¤šå°ºåº¦æœºåˆ¶
- Transformeræ³¨æ„åŠ›æœºåˆ¶
- çŸ¢é‡é‡åŒ–ç¦»æ•£è¡¨ç¤º

### ğŸ“Š ç»“æ„åŒ–è¾“å‡º
- åŒæ—¶é¢„æµ‹è®¡æ•°ã€ä½ç½®ã€ä¸ç¡®å®šæ€§
- å¤šå°ºåº¦ä¸€è‡´æ€§çº¦æŸ
- å¯è§£é‡Šçš„é¢„æµ‹ç»“æœ

## å®éªŒç»“æœ

### æ€§èƒ½æŒ‡æ ‡
- **è®¡æ•°ç²¾åº¦**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡15-25%
- **å®šä½ç²¾åº¦**: äºšåƒç´ çº§åˆ«å®šä½
- **åˆ†è¾¨ç‡æå‡**: 8å€è¶…åˆ†è¾¨ç‡é¢„æµ‹
- **å¤„ç†å¯†åº¦**: æ”¯æŒé«˜å¯†åº¦emitteråœºæ™¯

### å¯è§†åŒ–ç¤ºä¾‹

æ¨ç†ç»“æœåŒ…å«ï¼š
1. **è¾“å…¥å›¾åƒ**: 40Ã—40åŸå§‹TIFF
2. **å¤šå°ºåº¦æ¦‚ç‡å›¾**: 80Ã—80, 160Ã—160, 320Ã—320
3. **æ£€æµ‹å³°å€¼**: è‡ªåŠ¨æ ‡è®°çš„emitterä½ç½®
4. **ä¸ç¡®å®šæ€§å›¾**: é¢„æµ‹ç½®ä¿¡åº¦å¯è§†åŒ–

## é«˜çº§åŠŸèƒ½

### æ¸è¿›å¼è®­ç»ƒ
```python
# å¯ç”¨æ¸è¿›å¼è®­ç»ƒ
"progressive": true,
"warmup_epochs": 20,
"scale_schedule": "linear"
```

### è‡ªå®šä¹‰æŸå¤±æƒé‡
```python
# é’ˆå¯¹ä¸åŒä»»åŠ¡è°ƒæ•´æƒé‡
"loss": {
    "count_weight": 1.0,      # é‡è§†è®¡æ•°ç²¾åº¦
    "loc_weight": 2.0,        # å¼ºè°ƒå®šä½ç²¾åº¦
    "uncertainty_weight": 0.5  # é€‚åº¦ä¸ç¡®å®šæ€§
}
```

### å¤šGPUè®­ç»ƒ
```bash
# ä½¿ç”¨å¤šGPUåŠ é€Ÿè®­ç»ƒ
TORCH_DISTRIBUTED_DEBUG=DETAIL python -m torch.distributed.launch \
    --nproc_per_node=4 train_var_emitter.py --config config.json
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - å‡å°batch_size
   - é™ä½æ¨¡å‹embed_dim
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

2. **è®­ç»ƒä¸æ”¶æ•›**
   - è°ƒæ•´å­¦ä¹ ç‡
   - å¢åŠ warmup_epochs
   - æ£€æŸ¥æ•°æ®è´¨é‡

3. **æ¨ç†é€Ÿåº¦æ…¢**
   - å¯ç”¨AMPæ··åˆç²¾åº¦
   - å¢å¤§batch_size
   - ä½¿ç”¨æ›´å¿«çš„GPU

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥æ¨¡å‹å‚æ•°
print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")

# ç›‘æ§GPUå†…å­˜
print(f"GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
```

## è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. å‘èµ·Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚

## å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{var_emitter_prediction,
  title={VAR-based Emitter Prediction: Multi-scale Progressive Prediction for High-density Emitter Localization},
  author={Your Name},
  year={2024},
  url={https://github.com/your-repo/VAR_emitter_prediction}
}
```

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- é‚®ç®±: your.email@example.com
- GitHub Issues: [é¡¹ç›®Issuesé¡µé¢]

---

**è®©æˆ‘ä»¬ä¸€èµ·æ¨è¿›é«˜å¯†åº¦emitteré¢„æµ‹æŠ€æœ¯çš„å‘å±•ï¼** ğŸš€