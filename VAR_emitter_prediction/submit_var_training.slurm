#!/bin/bash
#SBATCH --job-name=var_emitter_training
#SBATCH --output=logs/var_training_%j.out
#SBATCH --error=logs/var_training_%j.err
#SBATCH --time=24:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --partition=cpu1
#SBATCH --gres=gpu:1

# VAR Emitteré¢„æµ‹æ¨¡å‹è®­ç»ƒSLURMè„šæœ¬
# æäº¤æ–¹å¼: sbatch submit_var_training.slurm

echo "======================================"
echo "ğŸš€ VAR Emitterè®­ç»ƒä½œä¸šå¼€å§‹"
echo "ä½œä¸šID: $SLURM_JOB_ID"
echo "èŠ‚ç‚¹: $SLURM_NODELIST"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo "======================================"

# è®¾ç½®å·¥ä½œç›®å½•
cd /home/guest/Others/DECODE_rewrite/VAR_emitter_prediction

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs
mkdir -p outputs
mkdir -p models

# æ¿€æ´»condaç¯å¢ƒï¼ˆæ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼‰
# source /path/to/conda/etc/profile.d/conda.sh
# conda activate pytorch_env

# è®¾ç½®Pythonè·¯å¾„
export PYTHONPATH="${PYTHONPATH}:/home/guest/Others/DECODE_rewrite"

# è®¾ç½®CUDAå¯è§è®¾å¤‡ï¼ˆå¦‚æœæœ‰å¤šGPUï¼‰
export CUDA_VISIBLE_DEVICES=0

# è®°å½•ç³»ç»Ÿä¿¡æ¯
echo "ğŸ“Š ç³»ç»Ÿä¿¡æ¯:"
echo "èŠ‚ç‚¹ä¿¡æ¯: $(hostname)"
echo "GPUä¿¡æ¯:"
nvidia-smi
echo "å†…å­˜ä¿¡æ¯:"
free -h
echo "CPUä¿¡æ¯:"
lscpu | grep "Model name"
echo "Pythonç‰ˆæœ¬:"
python --version
echo "PyTorchç‰ˆæœ¬:"
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda if torch.cuda.is_available() else "N/A"}')"
echo "======================================"

# æ£€æŸ¥é…ç½®æ–‡ä»¶
if [ ! -f "configs/config_true_var.json" ]; then
    echo "âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ configs/config_true_var.json ä¸å­˜åœ¨"
    exit 1
fi

# æ£€æŸ¥è®­ç»ƒè„šæœ¬
if [ ! -f "train_true_var.py" ]; then
    echo "âŒ é”™è¯¯: è®­ç»ƒè„šæœ¬ train_true_var.py ä¸å­˜åœ¨"
    exit 1
fi

echo "âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶æ£€æŸ¥å®Œæˆ"
echo "======================================"

# å¼€å§‹è®­ç»ƒ
echo "ğŸ¯ å¼€å§‹VAR Emitteræ¨¡å‹è®­ç»ƒ..."
echo "é…ç½®æ–‡ä»¶: configs/config_true_var.json"
echo "è®­ç»ƒè„šæœ¬: train_true_var.py"
echo "======================================"

# è¿è¡Œè®­ç»ƒï¼ˆæ·»åŠ è¯¦ç»†æ—¥å¿—ï¼‰
python train_true_var.py --config configs/config_true_var.json 2>&1 | tee logs/training_${SLURM_JOB_ID}.log

# æ£€æŸ¥è®­ç»ƒç»“æœ
TRAIN_EXIT_CODE=$?
echo "======================================"
if [ $TRAIN_EXIT_CODE -eq 0 ]; then
    echo "âœ… è®­ç»ƒæˆåŠŸå®Œæˆ!"
    echo "å®Œæˆæ—¶é—´: $(date)"
    
    # æ˜¾ç¤ºè¾“å‡ºç»Ÿè®¡
    echo "ğŸ“Š è®­ç»ƒç»“æœç»Ÿè®¡:"
    if [ -d "outputs" ]; then
        echo "è¾“å‡ºç›®å½•å¤§å°: $(du -sh outputs)"
        echo "æ¨¡å‹æ–‡ä»¶æ•°é‡: $(find outputs -name "*.pth" | wc -l)"
    fi
    
    if [ -d "logs/tensorboard" ]; then
        echo "TensorBoardæ—¥å¿—: $(du -sh logs/tensorboard)"
    fi
    
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : $TRAIN_EXIT_CODE"
    echo "è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—: logs/var_training_${SLURM_JOB_ID}.err"
fi

echo "======================================"
echo "ğŸ ä½œä¸šç»“æŸæ—¶é—´: $(date)"
echo "æ€»è¿è¡Œæ—¶é—´: $SECONDS ç§’"
echo "======================================"