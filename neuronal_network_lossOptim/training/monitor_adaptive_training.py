#!/usr/bin/env python3
"""
è‡ªé€‚åº”è®­ç»ƒç›‘æ§è„šæœ¬

åŠŸèƒ½:
1. å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
2. å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–
3. åˆ†ælossæ”¶æ•›è¶‹åŠ¿
4. ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
"""

import os
import json
import time
import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, List, Optional
import argparse
from datetime import datetime

class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self, checkpoint_path: str, output_dir: str = "monitoring_outputs"):
        self.checkpoint_path = checkpoint_path
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
    def load_checkpoint(self) -> Optional[Dict]:
        """åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®"""
        if not os.path.exists(self.checkpoint_path):
            print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {self.checkpoint_path}")
            return None
            
        try:
            import torch
            checkpoint = torch.load(self.checkpoint_path, map_location='cpu')
            return checkpoint
        except Exception as e:
            print(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None
    
    def plot_training_curves(self, checkpoint: Dict):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        train_losses = checkpoint.get('train_losses', [])
        val_losses = checkpoint.get('val_losses', [])
        lr_values = checkpoint.get('lr_values', [])
        
        if not train_losses:
            print("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæŸå¤±æ•°æ®")
            return
            
        epochs = range(len(train_losses))
        
        # åˆ›å»ºå­å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('è‡ªé€‚åº”è®­ç»ƒç›‘æ§æŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        # 1. æŸå¤±æ›²çº¿
        ax1.plot(epochs, train_losses, label='è®­ç»ƒæŸå¤±', color='blue', alpha=0.7)
        if val_losses:
            ax1.plot(epochs[:len(val_losses)], val_losses, label='éªŒè¯æŸå¤±', color='red', alpha=0.7)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('æŸå¤±å˜åŒ–æ›²çº¿')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å­¦ä¹ ç‡å˜åŒ–
        if lr_values:
            ax2.plot(epochs[:len(lr_values)], lr_values, color='green', linewidth=2)
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Learning Rate')
            ax2.set_title('å­¦ä¹ ç‡å˜åŒ–')
            ax2.set_yscale('log')
            ax2.grid(True, alpha=0.3)
        else:
            ax2.text(0.5, 0.5, 'æ— å­¦ä¹ ç‡æ•°æ®', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('å­¦ä¹ ç‡å˜åŒ–')
        
        # 3. æŸå¤±æ”¹å–„åˆ†æ
        if len(train_losses) > 10:
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            window_size = min(20, len(train_losses) // 5)
            train_ma = self._moving_average(train_losses, window_size)
            val_ma = self._moving_average(val_losses, window_size) if val_losses else []
            
            ma_epochs = range(window_size-1, len(train_losses))
            ax3.plot(ma_epochs, train_ma, label=f'è®­ç»ƒæŸå¤±MA({window_size})', color='blue')
            if val_ma:
                ax3.plot(ma_epochs[:len(val_ma)], val_ma, label=f'éªŒè¯æŸå¤±MA({window_size})', color='red')
            
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Loss (Moving Average)')
            ax3.set_title('æŸå¤±ç§»åŠ¨å¹³å‡')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('æŸå¤±ç§»åŠ¨å¹³å‡')
        
        # 4. æ”¶æ•›åˆ†æ
        if len(train_losses) > 5:
            # è®¡ç®—æŸå¤±å˜åŒ–ç‡
            train_diff = np.diff(train_losses)
            val_diff = np.diff(val_losses) if val_losses else []
            
            diff_epochs = range(1, len(train_losses))
            ax4.plot(diff_epochs, train_diff, label='è®­ç»ƒæŸå¤±å˜åŒ–ç‡', alpha=0.7, color='blue')
            if val_diff:
                ax4.plot(diff_epochs[:len(val_diff)], val_diff, label='éªŒè¯æŸå¤±å˜åŒ–ç‡', alpha=0.7, color='red')
            
            ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Loss Change')
            ax4.set_title('æŸå¤±å˜åŒ–ç‡')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('æŸå¤±å˜åŒ–ç‡')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plot_path = os.path.join(self.output_dir, f"training_curves_{timestamp}.png")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {plot_path}")
        
        plt.show()
        
    def _moving_average(self, data: List[float], window_size: int) -> List[float]:
        """è®¡ç®—ç§»åŠ¨å¹³å‡"""
        if len(data) < window_size:
            return data
            
        ma = []
        for i in range(window_size-1, len(data)):
            ma.append(np.mean(data[i-window_size+1:i+1]))
        return ma
    
    def analyze_convergence(self, checkpoint: Dict) -> Dict:
        """åˆ†ææ”¶æ•›æƒ…å†µ"""
        train_losses = checkpoint.get('train_losses', [])
        val_losses = checkpoint.get('val_losses', [])
        lr_values = checkpoint.get('lr_values', [])
        
        if not train_losses:
            return {"error": "æ²¡æœ‰è®­ç»ƒæ•°æ®"}
        
        analysis = {
            "total_epochs": len(train_losses),
            "initial_train_loss": train_losses[0] if train_losses else None,
            "final_train_loss": train_losses[-1] if train_losses else None,
            "best_train_loss": min(train_losses) if train_losses else None,
            "initial_val_loss": val_losses[0] if val_losses else None,
            "final_val_loss": val_losses[-1] if val_losses else None,
            "best_val_loss": min(val_losses) if val_losses else None,
            "initial_lr": lr_values[0] if lr_values else None,
            "final_lr": lr_values[-1] if lr_values else None,
            "min_lr": min(lr_values) if lr_values else None,
            "max_lr": max(lr_values) if lr_values else None
        }
        
        # è®¡ç®—æ”¹å–„ç‡
        if train_losses and len(train_losses) > 1:
            train_improvement = (train_losses[0] - train_losses[-1]) / train_losses[0] * 100
            analysis["train_improvement_percent"] = train_improvement
            
        if val_losses and len(val_losses) > 1:
            val_improvement = (val_losses[0] - val_losses[-1]) / val_losses[0] * 100
            analysis["val_improvement_percent"] = val_improvement
        
        # æ£€æµ‹åœæ»
        if len(train_losses) > 20:
            recent_losses = train_losses[-20:]
            loss_variance = np.var(recent_losses)
            analysis["recent_loss_variance"] = loss_variance
            analysis["is_stagnating"] = loss_variance < 0.001
        
        # å­¦ä¹ ç‡è°ƒæ•´æ¬¡æ•°
        if lr_values and len(lr_values) > 1:
            lr_changes = sum(1 for i in range(1, len(lr_values)) if abs(lr_values[i] - lr_values[i-1]) > 1e-8)
            analysis["lr_adjustment_count"] = lr_changes
        
        return analysis
    
    def generate_report(self, checkpoint: Dict):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        analysis = self.analyze_convergence(checkpoint)
        
        report = []
        report.append("=" * 60)
        report.append("è‡ªé€‚åº”è®­ç»ƒåˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        report.append("ğŸ“Š è®­ç»ƒåŸºæœ¬ä¿¡æ¯:")
        report.append(f"  æ€»è®­ç»ƒè½®æ•°: {analysis.get('total_epochs', 'N/A')}")
        report.append(f"  å½“å‰epoch: {checkpoint.get('epoch', 'N/A')}")
        report.append("")
        
        # æŸå¤±åˆ†æ
        report.append("ğŸ“ˆ æŸå¤±åˆ†æ:")
        if analysis.get('initial_train_loss') and analysis.get('final_train_loss'):
            report.append(f"  è®­ç»ƒæŸå¤±: {analysis['initial_train_loss']:.6f} â†’ {analysis['final_train_loss']:.6f}")
            if 'train_improvement_percent' in analysis:
                report.append(f"  è®­ç»ƒæ”¹å–„: {analysis['train_improvement_percent']:.2f}%")
        
        if analysis.get('initial_val_loss') and analysis.get('final_val_loss'):
            report.append(f"  éªŒè¯æŸå¤±: {analysis['initial_val_loss']:.6f} â†’ {analysis['final_val_loss']:.6f}")
            if 'val_improvement_percent' in analysis:
                report.append(f"  éªŒè¯æ”¹å–„: {analysis['val_improvement_percent']:.2f}%")
        
        if analysis.get('best_val_loss'):
            report.append(f"  æœ€ä½³éªŒè¯æŸå¤±: {analysis['best_val_loss']:.6f}")
        report.append("")
        
        # å­¦ä¹ ç‡åˆ†æ
        report.append("ğŸ¯ å­¦ä¹ ç‡åˆ†æ:")
        if analysis.get('initial_lr') and analysis.get('final_lr'):
            report.append(f"  å­¦ä¹ ç‡: {analysis['initial_lr']:.2e} â†’ {analysis['final_lr']:.2e}")
        if analysis.get('lr_adjustment_count'):
            report.append(f"  å­¦ä¹ ç‡è°ƒæ•´æ¬¡æ•°: {analysis['lr_adjustment_count']}")
        report.append("")
        
        # æ”¶æ•›çŠ¶æ€
        report.append("ğŸ” æ”¶æ•›çŠ¶æ€:")
        if 'is_stagnating' in analysis:
            status = "åœæ»" if analysis['is_stagnating'] else "æ­£å¸¸"
            report.append(f"  å½“å‰çŠ¶æ€: {status}")
            if analysis.get('recent_loss_variance'):
                report.append(f"  è¿‘æœŸæŸå¤±æ–¹å·®: {analysis['recent_loss_variance']:.6f}")
        
        # å»ºè®®
        report.append("")
        report.append("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        
        if analysis.get('is_stagnating', False):
            report.append("  âš ï¸  æ£€æµ‹åˆ°è®­ç»ƒåœæ»ï¼Œå»ºè®®:")
            report.append("     - å¢åŠ å­¦ä¹ ç‡")
            report.append("     - è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡")
            report.append("     - æ£€æŸ¥æ•°æ®è´¨é‡")
        
        if analysis.get('final_lr', 1) < 1e-6:
            report.append("  âš ï¸  å­¦ä¹ ç‡è¿‡å°ï¼Œå¯èƒ½éœ€è¦:")
            report.append("     - é‡æ–°å¯åŠ¨è®­ç»ƒ")
            report.append("     - ä½¿ç”¨æ›´å¤§çš„åˆå§‹å­¦ä¹ ç‡")
        
        if analysis.get('train_improvement_percent', 0) < 5:
            report.append("  âš ï¸  è®­ç»ƒæ”¹å–„æœ‰é™ï¼Œå»ºè®®:")
            report.append("     - å¢åŠ æ•°æ®é›†å¤§å°")
            report.append("     - è°ƒæ•´æ¨¡å‹æ¶æ„")
            report.append("     - æ£€æŸ¥æŸå¤±å‡½æ•°è®¾è®¡")
        
        report_text = "\n".join(report)
        print(report_text)
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(self.output_dir, f"training_report_{timestamp}.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\næŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return analysis
    
    def monitor_realtime(self, interval: int = 30):
        """å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦"""
        print(f"å¼€å§‹å®æ—¶ç›‘æ§ï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        last_epoch = -1
        
        try:
            while True:
                checkpoint = self.load_checkpoint()
                if checkpoint:
                    current_epoch = checkpoint.get('epoch', 0)
                    
                    if current_epoch > last_epoch:
                        print(f"\n[{datetime.now().strftime('%H:%M:%S')}] Epoch {current_epoch} å®Œæˆ")
                        
                        train_losses = checkpoint.get('train_losses', [])
                        val_losses = checkpoint.get('val_losses', [])
                        lr_values = checkpoint.get('lr_values', [])
                        
                        if train_losses:
                            print(f"  è®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")
                        if val_losses:
                            print(f"  éªŒè¯æŸå¤±: {val_losses[-1]:.6f}")
                        if lr_values:
                            print(f"  å½“å‰å­¦ä¹ ç‡: {lr_values[-1]:.2e}")
                        
                        last_epoch = current_epoch
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nç›‘æ§å·²åœæ­¢")

def main():
    parser = argparse.ArgumentParser(description='è‡ªé€‚åº”è®­ç»ƒç›‘æ§å·¥å…·')
    parser.add_argument('--checkpoint', '-c', 
                       default='outputs/training_results_adaptive/latest_checkpoint.pth',
                       help='æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', 
                       default='monitoring_outputs',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--mode', '-m', 
                       choices=['plot', 'report', 'monitor', 'all'],
                       default='all',
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--interval', '-i', 
                       type=int, default=30,
                       help='å®æ—¶ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    monitor = TrainingMonitor(args.checkpoint, args.output)
    
    if args.mode in ['plot', 'all']:
        print("ç”Ÿæˆè®­ç»ƒæ›²çº¿...")
        checkpoint = monitor.load_checkpoint()
        if checkpoint:
            monitor.plot_training_curves(checkpoint)
    
    if args.mode in ['report', 'all']:
        print("ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š...")
        checkpoint = monitor.load_checkpoint()
        if checkpoint:
            monitor.generate_report(checkpoint)
    
    if args.mode == 'monitor':
        monitor.monitor_realtime(args.interval)

if __name__ == '__main__':
    main()