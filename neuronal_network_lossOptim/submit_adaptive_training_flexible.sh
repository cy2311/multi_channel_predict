#!/bin/bash
#SBATCH --job-name=decode_adaptive
#SBATCH --output=logs/adaptive_%j.out
#SBATCH --error=logs/adaptive_%j.err
#SBATCH --time=48:00:00
#SBATCH --partition=cpu1
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

# ä½¿ç”¨æ–¹æ³•:
# sbatch submit_adaptive_training_flexible.sh
# sbatch --time=12:00:00 --mem=32G submit_adaptive_training_flexible.sh
# sbatch --gres=gpu:2 --cpus-per-task=32 submit_adaptive_training_flexible.sh

# å¯é…ç½®å‚æ•°
CONFIG_FILE="${CONFIG_FILE:-training/configs/train_config_adaptive.json}"
DEVICE="${DEVICE:-cuda}"
RESUME="${RESUME:-false}"
MONITOR_ONLY="${MONITOR_ONLY:-false}"

# æ‰“å°ä½œä¸šä¿¡æ¯
echo "==================== ä½œä¸šä¿¡æ¯ ===================="
echo "ä½œä¸šID: $SLURM_JOB_ID"
echo "ä½œä¸šåç§°: $SLURM_JOB_NAME"
echo "èŠ‚ç‚¹: $SLURM_NODELIST"
echo "GPU: $CUDA_VISIBLE_DEVICES"
echo "CPUæ ¸å¿ƒæ•°: $SLURM_CPUS_PER_TASK"
echo "å†…å­˜: $SLURM_MEM_PER_NODE MB"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo "å·¥ä½œç›®å½•: $(pwd)"
echo "é…ç½®æ–‡ä»¶: $CONFIG_FILE"
echo "è®¾å¤‡: $DEVICE"
echo "æ¢å¤è®­ç»ƒ: $RESUME"
echo "ä»…ç›‘æ§æ¨¡å¼: $MONITOR_ONLY"
echo "================================================="

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=$SLURM_LOCALID
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export PYTHONUNBUFFERED=1

# ç¯å¢ƒè®¾ç½®ï¼ˆæ ¹æ®é›†ç¾¤é…ç½®ä¿®æ”¹ï¼‰
# é€‰é¡¹1: Condaç¯å¢ƒ
# source ~/anaconda3/etc/profile.d/conda.sh
# conda activate decode_env

# é€‰é¡¹2: æ¨¡å—åŠ è½½
# module load cuda/11.8
# module load python/3.9
# module load pytorch/1.13

# é€‰é¡¹3: è™šæ‹Ÿç¯å¢ƒ
# source ~/venv/decode/bin/activate

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p logs
mkdir -p outputs/training_results_adaptive

# ç³»ç»Ÿæ£€æŸ¥
echo "\n==================== ç³»ç»Ÿæ£€æŸ¥ ===================="
echo "ä¸»æœºå: $(hostname)"
echo "æ“ä½œç³»ç»Ÿ: $(uname -a)"
echo "ç£ç›˜ç©ºé—´:"
df -h .
echo "\nGPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,memory.total,memory.used,utilization.gpu --format=csv,noheader,nounits
echo "\nPythonç¯å¢ƒ:"
echo "Pythonç‰ˆæœ¬: $(python --version)"
echo "PyTorchç‰ˆæœ¬: $(python -c 'import torch; print(torch.__version__)' 2>/dev/null || echo 'æœªå®‰è£…')"
echo "CUDAå¯ç”¨æ€§: $(python -c 'import torch; print(torch.cuda.is_available())' 2>/dev/null || echo 'æ£€æŸ¥å¤±è´¥')"
echo "GPUæ•°é‡: $(python -c 'import torch; print(torch.cuda.device_count())' 2>/dev/null || echo '0')"
echo "================================================="

# è¿›å…¥é¡¹ç›®ç›®å½•
cd /home/guest/Others/DECODE_rewrite/neuronal_network_lossOptim || {
    echo "é”™è¯¯: æ— æ³•è¿›å…¥é¡¹ç›®ç›®å½•"
    exit 1
}

# æ£€æŸ¥é…ç½®æ–‡ä»¶
if [ ! -f "$CONFIG_FILE" ]; then
    echo "é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $CONFIG_FILE"
    exit 1
fi

# æ„å»ºè®­ç»ƒå‘½ä»¤
TRAIN_CMD="python start_adaptive_training.py --config $CONFIG_FILE"

if [ "$RESUME" = "true" ]; then
    TRAIN_CMD="$TRAIN_CMD --resume"
fi

if [ "$MONITOR_ONLY" = "true" ]; then
    TRAIN_CMD="$TRAIN_CMD --monitor-only"
fi

# è¿è¡Œè®­ç»ƒ
echo "\n==================== å¼€å§‹è®­ç»ƒ ===================="
echo "æ‰§è¡Œå‘½ä»¤: $TRAIN_CMD"
echo "================================================="

# ä½¿ç”¨timeouté˜²æ­¢ä½œä¸šè¶…æ—¶ (é»˜è®¤47å°æ—¶ï¼Œæ¯”SLURMæ—¶é—´é™åˆ¶å°‘1å°æ—¶)
# å¦‚æœéœ€è¦è‡ªå®šä¹‰è¶…æ—¶æ—¶é—´ï¼Œå¯ä»¥è®¾ç½®TIMEOUT_HOURSç¯å¢ƒå˜é‡
TIMEOUT_HOURS=${TIMEOUT_HOURS:-47}
timeout ${TIMEOUT_HOURS}h $TRAIN_CMD
EXIT_CODE=$?

# æ£€æŸ¥ç»“æœ
echo "\n==================== è®­ç»ƒç»“æœ ===================="
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼"
    echo "ğŸ“ ç»“æœä¿å­˜åœ¨: outputs/training_results_adaptive/"
    echo "ğŸ“Š TensorBoardæ—¥å¿—: outputs/training_results_adaptive/tensorboard/"
    echo "ğŸ’¾ æ£€æŸ¥ç‚¹æ–‡ä»¶: outputs/training_results_adaptive/checkpoints/"
elif [ $EXIT_CODE -eq 124 ]; then
    echo "â° è®­ç»ƒå› è¶…æ—¶è€Œç»ˆæ­¢"
    echo "ğŸ’¡ å»ºè®®: å¢åŠ æ—¶é—´é™åˆ¶æˆ–ä½¿ç”¨æ£€æŸ¥ç‚¹æ¢å¤"
elif [ $EXIT_CODE -eq 130 ]; then
    echo "ğŸ›‘ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­"
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : $EXIT_CODE"
    echo "ğŸ“‹ è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—: logs/adaptive_${SLURM_JOB_ID}.err"
fi

# æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶ä¿¡æ¯
if [ -d "outputs/training_results_adaptive" ]; then
    echo "\nğŸ“‚ è¾“å‡ºæ–‡ä»¶åˆ—è¡¨:"
    ls -la outputs/training_results_adaptive/
fi

echo "\nç»“æŸæ—¶é—´: $(date)"
echo "æ€»è¿è¡Œæ—¶é—´: $SECONDS ç§’"
echo "================================================="

exit $EXIT_CODE