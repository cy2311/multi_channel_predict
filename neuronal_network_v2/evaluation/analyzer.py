"""æ€§èƒ½åˆ†æå™¨æ¨¡å—

è¯¥æ¨¡å—æä¾›äº†æ·±åº¦æ€§èƒ½åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ€§èƒ½ç“¶é¢ˆåˆ†æ
- ç»Ÿè®¡åˆ†æ
- è¶‹åŠ¿åˆ†æ
- å¼‚å¸¸æ£€æµ‹
- æ€§èƒ½ä¼˜åŒ–å»ºè®®
"""

import numpy as np
import pandas as pd
from scipy import stats
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from typing import Dict, List, Optional, Union, Tuple, Any
import logging
from dataclasses import dataclass, asdict
from pathlib import Path
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

from .metrics import DetectionMetrics, LocalizationMetrics, PhotonMetrics, ComprehensiveMetrics
from ..utils.logging_utils import get_logger
from ..utils.math_utils import calculate_statistics
from ..utils.io_utils import write_json, create_directory
from ..utils.visualization import save_plot

logger = get_logger(__name__)


@dataclass
class PerformanceProfile:
    """æ€§èƒ½æ¦‚å†µ"""
    model_name: str
    dataset_info: Dict[str, Any]
    overall_score: float
    detection_score: float
    localization_score: float
    photon_score: float
    efficiency_score: float
    stability_score: float
    bottlenecks: List[str]
    recommendations: List[str]
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


@dataclass
class StatisticalAnalysis:
    """ç»Ÿè®¡åˆ†æç»“æœ"""
    metric_name: str
    mean: float
    std: float
    median: float
    q25: float
    q75: float
    min_val: float
    max_val: float
    skewness: float
    kurtosis: float
    normality_test: Dict[str, float]
    outliers: List[int]
    confidence_interval: Tuple[float, float]


@dataclass
class TrendAnalysis:
    """è¶‹åŠ¿åˆ†æç»“æœ"""
    metric_name: str
    trend_direction: str  # 'increasing', 'decreasing', 'stable'
    trend_strength: float
    correlation_coefficient: float
    p_value: float
    seasonal_pattern: bool
    change_points: List[int]
    forecast: Optional[List[float]] = None


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨
        """
        self.analysis_history = []
        logger.info("æ€§èƒ½åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_performance(self,
                          results: Dict[str, Any],
                          reference_results: Optional[Dict[str, Any]] = None) -> PerformanceProfile:
        """
        åˆ†ææ¨¡å‹æ€§èƒ½
        
        Args:
            results: è¯„ä¼°ç»“æœ
            reference_results: å‚è€ƒç»“æœï¼ˆç”¨äºæ¯”è¾ƒï¼‰
            
        Returns:
            PerformanceProfile: æ€§èƒ½æ¦‚å†µ
        """
        logger.info("å¼€å§‹æ€§èƒ½åˆ†æ")
        
        # æå–æŒ‡æ ‡
        detection_metrics = results.get('detection_metrics', {})
        localization_metrics = results.get('localization_metrics', {})
        photon_metrics = results.get('photon_metrics', {})
        comprehensive_metrics = results.get('comprehensive_metrics', {})
        
        # è®¡ç®—å„é¡¹å¾—åˆ†
        detection_score = self._calculate_detection_score(detection_metrics)
        localization_score = self._calculate_localization_score(localization_metrics)
        photon_score = self._calculate_photon_score(photon_metrics)
        efficiency_score = self._calculate_efficiency_score(results)
        stability_score = self._calculate_stability_score(results)
        
        # è®¡ç®—æ€»ä½“å¾—åˆ†
        overall_score = np.mean([detection_score, localization_score, photon_score, efficiency_score])
        
        # è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
        bottlenecks = self._identify_bottlenecks({
            'detection': detection_score,
            'localization': localization_score,
            'photon': photon_score,
            'efficiency': efficiency_score,
            'stability': stability_score
        })
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self._generate_recommendations(
            detection_metrics, localization_metrics, photon_metrics, bottlenecks
        )
        
        # åˆ›å»ºæ€§èƒ½æ¦‚å†µ
        profile = PerformanceProfile(
            model_name=results.get('model_name', 'Unknown'),
            dataset_info={
                'name': results.get('dataset_name', 'Unknown'),
                'num_samples': results.get('num_samples', 0),
                'processing_time': results.get('processing_time', 0),
                'memory_usage': results.get('memory_usage', 0)
            },
            overall_score=overall_score,
            detection_score=detection_score,
            localization_score=localization_score,
            photon_score=photon_score,
            efficiency_score=efficiency_score,
            stability_score=stability_score,
            bottlenecks=bottlenecks,
            recommendations=recommendations,
            timestamp=datetime.now().isoformat()
        )
        
        self.analysis_history.append(profile)
        logger.info(f"æ€§èƒ½åˆ†æå®Œæˆï¼Œæ€»ä½“å¾—åˆ†: {overall_score:.3f}")
        
        return profile
    
    def _calculate_detection_score(self, metrics: Dict[str, Any]) -> float:
        """
        è®¡ç®—æ£€æµ‹å¾—åˆ†
        
        Args:
            metrics: æ£€æµ‹æŒ‡æ ‡
            
        Returns:
            float: æ£€æµ‹å¾—åˆ† (0-1)
        """
        precision = metrics.get('precision', 0)
        recall = metrics.get('recall', 0)
        f1_score = metrics.get('f1_score', 0)
        jaccard = metrics.get('jaccard_index', 0)
        
        # åŠ æƒå¹³å‡
        weights = [0.3, 0.3, 0.3, 0.1]
        scores = [precision, recall, f1_score, jaccard]
        
        return np.average(scores, weights=weights)
    
    def _calculate_localization_score(self, metrics: Dict[str, Any]) -> float:
        """
        è®¡ç®—å®šä½å¾—åˆ†
        
        Args:
            metrics: å®šä½æŒ‡æ ‡
            
        Returns:
            float: å®šä½å¾—åˆ† (0-1)
        """
        rmse_x = metrics.get('rmse_x', float('inf'))
        rmse_y = metrics.get('rmse_y', float('inf'))
        rmse_z = metrics.get('rmse_z', float('inf'))
        
        # è½¬æ¢ä¸ºå¾—åˆ†ï¼ˆRMSEè¶Šå°å¾—åˆ†è¶Šé«˜ï¼‰
        # å‡è®¾100nmä»¥ä¸‹ä¸ºä¼˜ç§€ï¼Œ500nmä»¥ä¸‹ä¸ºè‰¯å¥½
        def rmse_to_score(rmse):
            if rmse <= 100:
                return 1.0
            elif rmse <= 500:
                return 1.0 - (rmse - 100) / 400 * 0.5
            else:
                return max(0, 0.5 - (rmse - 500) / 1000 * 0.5)
        
        score_x = rmse_to_score(rmse_x)
        score_y = rmse_to_score(rmse_y)
        score_z = rmse_to_score(rmse_z)
        
        # XYæ–¹å‘æƒé‡æ›´é«˜
        return np.average([score_x, score_y, score_z], weights=[0.4, 0.4, 0.2])
    
    def _calculate_photon_score(self, metrics: Dict[str, Any]) -> float:
        """
        è®¡ç®—å…‰å­æ•°å¾—åˆ†
        
        Args:
            metrics: å…‰å­æ•°æŒ‡æ ‡
            
        Returns:
            float: å…‰å­æ•°å¾—åˆ† (0-1)
        """
        correlation = metrics.get('correlation', 0)
        relative_error = metrics.get('relative_error', 1)
        
        # ç›¸å…³æ€§å¾—åˆ†
        corr_score = max(0, correlation)
        
        # ç›¸å¯¹è¯¯å·®å¾—åˆ†
        error_score = max(0, 1 - abs(relative_error))
        
        return np.mean([corr_score, error_score])
    
    def _calculate_efficiency_score(self, results: Dict[str, Any]) -> float:
        """
        è®¡ç®—æ•ˆç‡å¾—åˆ†
        
        Args:
            results: è¯„ä¼°ç»“æœ
            
        Returns:
            float: æ•ˆç‡å¾—åˆ† (0-1)
        """
        processing_time = results.get('processing_time', float('inf'))
        memory_usage = results.get('memory_usage', float('inf'))
        num_samples = results.get('num_samples', 1)
        
        # æ¯æ ·æœ¬å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        time_per_sample = processing_time / max(num_samples, 1)
        
        # æ—¶é—´æ•ˆç‡å¾—åˆ†ï¼ˆå‡è®¾1ç§’/æ ·æœ¬ä¸ºåŸºå‡†ï¼‰
        time_score = max(0, 1 - time_per_sample / 10)
        
        # å†…å­˜æ•ˆç‡å¾—åˆ†ï¼ˆå‡è®¾1GBä¸ºåŸºå‡†ï¼‰
        memory_score = max(0, 1 - memory_usage / 1024)
        
        return np.mean([time_score, memory_score])
    
    def _calculate_stability_score(self, results: Dict[str, Any]) -> float:
        """
        è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
        
        Args:
            results: è¯„ä¼°ç»“æœ
            
        Returns:
            float: ç¨³å®šæ€§å¾—åˆ† (0-1)
        """
        # åŸºäºå®šä½æŒ‡æ ‡çš„æ ‡å‡†å·®è®¡ç®—ç¨³å®šæ€§
        localization_metrics = results.get('localization_metrics', {})
        
        std_x = localization_metrics.get('std_x', float('inf'))
        std_y = localization_metrics.get('std_y', float('inf'))
        std_z = localization_metrics.get('std_z', float('inf'))
        
        # æ ‡å‡†å·®è¶Šå°ï¼Œç¨³å®šæ€§è¶Šå¥½
        def std_to_score(std):
            if std <= 50:
                return 1.0
            elif std <= 200:
                return 1.0 - (std - 50) / 150 * 0.5
            else:
                return max(0, 0.5 - (std - 200) / 300 * 0.5)
        
        score_x = std_to_score(std_x)
        score_y = std_to_score(std_y)
        score_z = std_to_score(std_z)
        
        return np.mean([score_x, score_y, score_z])
    
    def _identify_bottlenecks(self, scores: Dict[str, float]) -> List[str]:
        """
        è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
        
        Args:
            scores: å„é¡¹å¾—åˆ†
            
        Returns:
            List[str]: ç“¶é¢ˆåˆ—è¡¨
        """
        bottlenecks = []
        threshold = 0.6  # å¾—åˆ†é˜ˆå€¼
        
        for metric, score in scores.items():
            if score < threshold:
                bottlenecks.append(f"{metric}æ€§èƒ½ä¸è¶³ (å¾—åˆ†: {score:.3f})")
        
        # æ‰¾å‡ºæœ€ä½å¾—åˆ†
        min_score = min(scores.values())
        min_metrics = [k for k, v in scores.items() if v == min_score]
        
        if min_score < 0.8:
            bottlenecks.append(f"ä¸»è¦ç“¶é¢ˆ: {', '.join(min_metrics)}")
        
        return bottlenecks
    
    def _generate_recommendations(self,
                                detection_metrics: Dict[str, Any],
                                localization_metrics: Dict[str, Any],
                                photon_metrics: Dict[str, Any],
                                bottlenecks: List[str]) -> List[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®
        
        Args:
            detection_metrics: æ£€æµ‹æŒ‡æ ‡
            localization_metrics: å®šä½æŒ‡æ ‡
            photon_metrics: å…‰å­æ•°æŒ‡æ ‡
            bottlenecks: ç“¶é¢ˆåˆ—è¡¨
            
        Returns:
            List[str]: å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        # æ£€æµ‹æ€§èƒ½å»ºè®®
        precision = detection_metrics.get('precision', 0)
        recall = detection_metrics.get('recall', 0)
        
        if precision < 0.8:
            recommendations.append("å»ºè®®è°ƒæ•´æ£€æµ‹é˜ˆå€¼ä»¥æé«˜ç²¾ç¡®ç‡ï¼Œå‡å°‘å‡æ­£ä¾‹")
        if recall < 0.8:
            recommendations.append("å»ºè®®é™ä½æ£€æµ‹é˜ˆå€¼æˆ–æ”¹è¿›æ¨¡å‹ä»¥æé«˜å¬å›ç‡")
        if precision < 0.8 and recall < 0.8:
            recommendations.append("å»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–è°ƒæ•´ç½‘ç»œæ¶æ„")
        
        # å®šä½æ€§èƒ½å»ºè®®
        rmse_x = localization_metrics.get('rmse_x', 0)
        rmse_y = localization_metrics.get('rmse_y', 0)
        rmse_z = localization_metrics.get('rmse_z', 0)
        
        if max(rmse_x, rmse_y) > 200:
            recommendations.append("æ¨ªå‘å®šä½ç²¾åº¦ä¸è¶³ï¼Œå»ºè®®å¢åŠ è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡")
        if rmse_z > 500:
            recommendations.append("è½´å‘å®šä½ç²¾åº¦ä¸è¶³ï¼Œå»ºè®®æ”¹è¿›Zæ–¹å‘çš„ç‰¹å¾æå–")
        
        # å…‰å­æ•°å»ºè®®
        correlation = photon_metrics.get('correlation', 0)
        if correlation < 0.7:
            recommendations.append("å…‰å­æ•°é¢„æµ‹ç›¸å…³æ€§è¾ƒä½ï¼Œå»ºè®®æ”¹è¿›å…‰å­æ•°å›å½’åˆ†æ”¯")
        
        # é€šç”¨å»ºè®®
        if len(bottlenecks) > 2:
            recommendations.append("å¤šé¡¹æŒ‡æ ‡å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®è¿›è¡Œå…¨é¢çš„æ¨¡å‹ä¼˜åŒ–")
        
        if not recommendations:
            recommendations.append("æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥è¾¾åˆ°æ›´é«˜ç²¾åº¦")
        
        return recommendations
    
    def statistical_analysis(self, data: np.ndarray, metric_name: str) -> StatisticalAnalysis:
        """
        ç»Ÿè®¡åˆ†æ
        
        Args:
            data: æ•°æ®æ•°ç»„
            metric_name: æŒ‡æ ‡åç§°
            
        Returns:
            StatisticalAnalysis: ç»Ÿè®¡åˆ†æç»“æœ
        """
        logger.info(f"å¼€å§‹ç»Ÿè®¡åˆ†æ: {metric_name}")
        
        # åŸºæœ¬ç»Ÿè®¡é‡
        stats_dict = calculate_statistics(data)
        
        # æ­£æ€æ€§æ£€éªŒ
        if len(data) >= 3:
            shapiro_stat, shapiro_p = stats.shapiro(data)
            normality_test = {'shapiro_stat': shapiro_stat, 'shapiro_p': shapiro_p}
        else:
            normality_test = {'shapiro_stat': np.nan, 'shapiro_p': np.nan}
        
        # å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆIQRæ–¹æ³•ï¼‰
        q25, q75 = np.percentile(data, [25, 75])
        iqr = q75 - q25
        lower_bound = q25 - 1.5 * iqr
        upper_bound = q75 + 1.5 * iqr
        outliers = np.where((data < lower_bound) | (data > upper_bound))[0].tolist()
        
        # ç½®ä¿¡åŒºé—´ï¼ˆ95%ï¼‰
        if len(data) > 1:
            confidence_interval = stats.t.interval(
                0.95, len(data) - 1, 
                loc=stats_dict['mean'], 
                scale=stats.sem(data)
            )
        else:
            confidence_interval = (stats_dict['mean'], stats_dict['mean'])
        
        return StatisticalAnalysis(
            metric_name=metric_name,
            mean=stats_dict['mean'],
            std=stats_dict['std'],
            median=stats_dict['median'],
            q25=q25,
            q75=q75,
            min_val=stats_dict['min'],
            max_val=stats_dict['max'],
            skewness=stats_dict['skewness'],
            kurtosis=stats_dict['kurtosis'],
            normality_test=normality_test,
            outliers=outliers,
            confidence_interval=confidence_interval
        )
    
    def trend_analysis(self, data: np.ndarray, metric_name: str) -> TrendAnalysis:
        """
        è¶‹åŠ¿åˆ†æ
        
        Args:
            data: æ—¶é—´åºåˆ—æ•°æ®
            metric_name: æŒ‡æ ‡åç§°
            
        Returns:
            TrendAnalysis: è¶‹åŠ¿åˆ†æç»“æœ
        """
        logger.info(f"å¼€å§‹è¶‹åŠ¿åˆ†æ: {metric_name}")
        
        if len(data) < 3:
            logger.warning("æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ")
            return TrendAnalysis(
                metric_name=metric_name,
                trend_direction='unknown',
                trend_strength=0.0,
                correlation_coefficient=0.0,
                p_value=1.0,
                seasonal_pattern=False,
                change_points=[]
            )
        
        # æ—¶é—´ç´¢å¼•
        time_index = np.arange(len(data))
        
        # çº¿æ€§è¶‹åŠ¿åˆ†æ
        correlation_coef, p_value = stats.pearsonr(time_index, data)
        
        # è¶‹åŠ¿æ–¹å‘
        if p_value < 0.05:
            if correlation_coef > 0:
                trend_direction = 'increasing'
            else:
                trend_direction = 'decreasing'
        else:
            trend_direction = 'stable'
        
        # è¶‹åŠ¿å¼ºåº¦
        trend_strength = abs(correlation_coef)
        
        # å˜ç‚¹æ£€æµ‹ï¼ˆç®€å•æ–¹æ³•ï¼šæ»‘åŠ¨çª—å£æ–¹å·®ï¼‰
        change_points = self._detect_change_points(data)
        
        # å­£èŠ‚æ€§æ¨¡å¼æ£€æµ‹ï¼ˆç®€å•æ–¹æ³•ï¼šè‡ªç›¸å…³ï¼‰
        seasonal_pattern = self._detect_seasonality(data)
        
        return TrendAnalysis(
            metric_name=metric_name,
            trend_direction=trend_direction,
            trend_strength=trend_strength,
            correlation_coefficient=correlation_coef,
            p_value=p_value,
            seasonal_pattern=seasonal_pattern,
            change_points=change_points
        )
    
    def _detect_change_points(self, data: np.ndarray, window_size: int = 5) -> List[int]:
        """
        æ£€æµ‹å˜ç‚¹
        
        Args:
            data: æ•°æ®æ•°ç»„
            window_size: çª—å£å¤§å°
            
        Returns:
            List[int]: å˜ç‚¹ç´¢å¼•åˆ—è¡¨
        """
        if len(data) < window_size * 2:
            return []
        
        change_points = []
        
        for i in range(window_size, len(data) - window_size):
            left_window = data[i-window_size:i]
            right_window = data[i:i+window_size]
            
            # ä½¿ç”¨tæ£€éªŒæ£€æµ‹å‡å€¼å˜åŒ–
            try:
                t_stat, p_value = stats.ttest_ind(left_window, right_window)
                if p_value < 0.01:  # ä¸¥æ ¼çš„é˜ˆå€¼
                    change_points.append(i)
            except:
                continue
        
        return change_points
    
    def _detect_seasonality(self, data: np.ndarray) -> bool:
        """
        æ£€æµ‹å­£èŠ‚æ€§æ¨¡å¼
        
        Args:
            data: æ•°æ®æ•°ç»„
            
        Returns:
            bool: æ˜¯å¦å­˜åœ¨å­£èŠ‚æ€§
        """
        if len(data) < 10:
            return False
        
        # è®¡ç®—è‡ªç›¸å…³
        try:
            autocorr = np.correlate(data - np.mean(data), data - np.mean(data), mode='full')
            autocorr = autocorr[autocorr.size // 2:]
            autocorr = autocorr / autocorr[0]
            
            # å¯»æ‰¾æ˜¾è‘—çš„å‘¨æœŸæ€§å³°å€¼
            for lag in range(2, min(len(autocorr) // 2, 20)):
                if autocorr[lag] > 0.3:  # é˜ˆå€¼
                    return True
            
            return False
        except:
            return False
    
    def anomaly_detection(self, data: np.ndarray, method: str = 'isolation') -> Dict[str, Any]:
        """
        å¼‚å¸¸æ£€æµ‹
        
        Args:
            data: æ•°æ®æ•°ç»„
            method: æ£€æµ‹æ–¹æ³• ('isolation', 'statistical', 'clustering')
            
        Returns:
            Dict[str, Any]: å¼‚å¸¸æ£€æµ‹ç»“æœ
        """
        logger.info(f"å¼€å§‹å¼‚å¸¸æ£€æµ‹ï¼Œæ–¹æ³•: {method}")
        
        if len(data) < 5:
            return {'anomalies': [], 'method': method, 'message': 'æ•°æ®ç‚¹å¤ªå°‘'}
        
        anomalies = []
        
        if method == 'statistical':
            # åŸºäºç»Ÿè®¡çš„å¼‚å¸¸æ£€æµ‹ï¼ˆ3-sigmaè§„åˆ™ï¼‰
            mean = np.mean(data)
            std = np.std(data)
            threshold = 3 * std
            
            anomalies = np.where(np.abs(data - mean) > threshold)[0].tolist()
            
        elif method == 'clustering':
            # åŸºäºèšç±»çš„å¼‚å¸¸æ£€æµ‹
            try:
                # æ ‡å‡†åŒ–æ•°æ®
                scaler = StandardScaler()
                data_scaled = scaler.fit_transform(data.reshape(-1, 1))
                
                # DBSCANèšç±»
                dbscan = DBSCAN(eps=0.5, min_samples=3)
                labels = dbscan.fit_predict(data_scaled)
                
                # å™ªå£°ç‚¹ï¼ˆæ ‡ç­¾ä¸º-1ï¼‰è§†ä¸ºå¼‚å¸¸
                anomalies = np.where(labels == -1)[0].tolist()
                
            except Exception as e:
                logger.error(f"èšç±»å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
                anomalies = []
        
        else:  # isolation forest (ç®€åŒ–ç‰ˆ)
            # ç®€åŒ–çš„å­¤ç«‹æ£®æ—æ–¹æ³•
            q25, q75 = np.percentile(data, [25, 75])
            iqr = q75 - q25
            lower_bound = q25 - 2.5 * iqr
            upper_bound = q75 + 2.5 * iqr
            
            anomalies = np.where((data < lower_bound) | (data > upper_bound))[0].tolist()
        
        return {
            'anomalies': anomalies,
            'anomaly_count': len(anomalies),
            'anomaly_rate': len(anomalies) / len(data),
            'method': method,
            'anomaly_values': data[anomalies].tolist() if anomalies else []
        }
    
    def compare_models(self, profiles: List[PerformanceProfile]) -> Dict[str, Any]:
        """
        æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½
        
        Args:
            profiles: æ€§èƒ½æ¦‚å†µåˆ—è¡¨
            
        Returns:
            Dict[str, Any]: æ¯”è¾ƒç»“æœ
        """
        logger.info(f"å¼€å§‹æ¯”è¾ƒ {len(profiles)} ä¸ªæ¨¡å‹")
        
        if len(profiles) < 2:
            return {'message': 'éœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹è¿›è¡Œæ¯”è¾ƒ'}
        
        # æå–å„é¡¹å¾—åˆ†
        model_names = [p.model_name for p in profiles]
        overall_scores = [p.overall_score for p in profiles]
        detection_scores = [p.detection_score for p in profiles]
        localization_scores = [p.localization_score for p in profiles]
        photon_scores = [p.photon_score for p in profiles]
        efficiency_scores = [p.efficiency_score for p in profiles]
        
        # æ’å
        overall_ranking = sorted(enumerate(overall_scores), key=lambda x: x[1], reverse=True)
        
        # æœ€ä½³æ¨¡å‹
        best_model_idx = overall_ranking[0][0]
        best_model = profiles[best_model_idx]
        
        # å„é¡¹æŒ‡æ ‡çš„æœ€ä½³æ¨¡å‹
        best_detection = model_names[np.argmax(detection_scores)]
        best_localization = model_names[np.argmax(localization_scores)]
        best_photon = model_names[np.argmax(photon_scores)]
        best_efficiency = model_names[np.argmax(efficiency_scores)]
        
        # ç»Ÿè®¡åˆ†æ
        score_stats = {
            'overall': calculate_statistics(np.array(overall_scores)),
            'detection': calculate_statistics(np.array(detection_scores)),
            'localization': calculate_statistics(np.array(localization_scores)),
            'photon': calculate_statistics(np.array(photon_scores)),
            'efficiency': calculate_statistics(np.array(efficiency_scores))
        }
        
        return {
            'model_count': len(profiles),
            'best_overall_model': {
                'name': best_model.model_name,
                'score': best_model.overall_score,
                'rank': 1
            },
            'rankings': [
                {
                    'rank': i + 1,
                    'model': model_names[idx],
                    'score': score
                }
                for i, (idx, score) in enumerate(overall_ranking)
            ],
            'category_leaders': {
                'detection': best_detection,
                'localization': best_localization,
                'photon': best_photon,
                'efficiency': best_efficiency
            },
            'statistics': score_stats,
            'recommendations': self._generate_comparison_recommendations(profiles)
        }
    
    def _generate_comparison_recommendations(self, profiles: List[PerformanceProfile]) -> List[str]:
        """
        ç”Ÿæˆæ¨¡å‹æ¯”è¾ƒå»ºè®®
        
        Args:
            profiles: æ€§èƒ½æ¦‚å†µåˆ—è¡¨
            
        Returns:
            List[str]: å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        # åˆ†æå¾—åˆ†åˆ†å¸ƒ
        overall_scores = [p.overall_score for p in profiles]
        score_range = max(overall_scores) - min(overall_scores)
        
        if score_range < 0.1:
            recommendations.append("å„æ¨¡å‹æ€§èƒ½ç›¸è¿‘ï¼Œå»ºè®®è€ƒè™‘è®¡ç®—æ•ˆç‡å’Œèµ„æºæ¶ˆè€—")
        elif score_range > 0.3:
            recommendations.append("æ¨¡å‹æ€§èƒ½å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®é€‰æ‹©é«˜åˆ†æ¨¡å‹å¹¶åˆ†æä½åˆ†æ¨¡å‹çš„é—®é¢˜")
        
        # åˆ†æç“¶é¢ˆæ¨¡å¼
        all_bottlenecks = []
        for profile in profiles:
            all_bottlenecks.extend(profile.bottlenecks)
        
        if len(all_bottlenecks) > len(profiles):
            recommendations.append("å¤šæ•°æ¨¡å‹å­˜åœ¨æ€§èƒ½ç“¶é¢ˆï¼Œå»ºè®®è¿›è¡Œç³»ç»Ÿæ€§ä¼˜åŒ–")
        
        return recommendations
    
    def generate_analysis_report(self,
                               profile: PerformanceProfile,
                               output_dir: str,
                               include_plots: bool = True) -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            profile: æ€§èƒ½æ¦‚å†µ
            output_dir: è¾“å‡ºç›®å½•
            include_plots: æ˜¯å¦åŒ…å«å›¾è¡¨
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        logger.info("ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š")
        
        output_path = Path(output_dir)
        create_directory(str(output_path))
        
        # ä¿å­˜JSONæ•°æ®
        profile_path = output_path / "performance_profile.json"
        save_json(profile.to_dict(), str(profile_path))
        
        # ç”Ÿæˆå›¾è¡¨
        if include_plots:
            self._generate_analysis_plots(profile, output_path)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        report_path = self._generate_html_analysis_report(profile, output_path)
        
        logger.info(f"åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
    
    def _generate_analysis_plots(self, profile: PerformanceProfile, output_path: Path):
        """
        ç”Ÿæˆåˆ†æå›¾è¡¨
        
        Args:
            profile: æ€§èƒ½æ¦‚å†µ
            output_path: è¾“å‡ºè·¯å¾„
        """
        # å¾—åˆ†é›·è¾¾å›¾
        categories = ['æ£€æµ‹', 'å®šä½', 'å…‰å­æ•°', 'æ•ˆç‡', 'ç¨³å®šæ€§']
        scores = [
            profile.detection_score,
            profile.localization_score,
            profile.photon_score,
            profile.efficiency_score,
            profile.stability_score
        ]
        
        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))
        
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        scores += scores[:1]  # é—­åˆå›¾å½¢
        angles += angles[:1]
        
        ax.plot(angles, scores, 'o-', linewidth=2, color='blue')
        ax.fill(angles, scores, alpha=0.25, color='blue')
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories)
        ax.set_ylim(0, 1)
        ax.set_title(f'{profile.model_name} æ€§èƒ½é›·è¾¾å›¾', y=1.08, fontsize=14)
        
        plt.tight_layout()
        save_plot(fig, str(output_path / "performance_radar.png"))
        plt.close(fig)
        
        # å¾—åˆ†æ¡å½¢å›¾
        fig, ax = plt.subplots(figsize=(10, 6))
        
        bars = ax.bar(categories, scores[:-1], color=['red', 'green', 'blue', 'orange', 'purple'], alpha=0.7)
        ax.set_ylabel('å¾—åˆ†')
        ax.set_title(f'{profile.model_name} å„é¡¹æ€§èƒ½å¾—åˆ†')
        ax.set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars, scores[:-1]):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                   f'{score:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        save_plot(fig, str(output_path / "performance_bars.png"))
        plt.close(fig)
    
    def _generate_html_analysis_report(self, profile: PerformanceProfile, output_path: Path) -> Path:
        """
        ç”ŸæˆHTMLåˆ†ææŠ¥å‘Š
        
        Args:
            profile: æ€§èƒ½æ¦‚å†µ
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            Path: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ€§èƒ½åˆ†ææŠ¥å‘Š - {profile.model_name}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .section {{ margin: 20px 0; }}
                .score-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
                .score-card {{ border: 1px solid #ddd; padding: 15px; border-radius: 5px; text-align: center; }}
                .score-value {{ font-size: 2em; font-weight: bold; color: #007bff; }}
                .bottleneck {{ background-color: #fff3cd; border: 1px solid #ffeaa7; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                .recommendation {{ background-color: #d1ecf1; border: 1px solid #bee5eb; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                .chart {{ text-align: center; margin: 20px 0; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>æ€§èƒ½åˆ†ææŠ¥å‘Š</h1>
                <h2>{profile.model_name}</h2>
                <p><strong>åˆ†ææ—¶é—´:</strong> {profile.timestamp}</p>
                <p><strong>æ•°æ®é›†:</strong> {profile.dataset_info['name']}</p>
                <p><strong>æ ·æœ¬æ•°é‡:</strong> {profile.dataset_info['num_samples']}</p>
            </div>
            
            <div class="section">
                <h2>æ€§èƒ½å¾—åˆ†æ¦‚è§ˆ</h2>
                <div class="score-grid">
                    <div class="score-card">
                        <div>æ€»ä½“å¾—åˆ†</div>
                        <div class="score-value">{profile.overall_score:.3f}</div>
                    </div>
                    <div class="score-card">
                        <div>æ£€æµ‹å¾—åˆ†</div>
                        <div class="score-value">{profile.detection_score:.3f}</div>
                    </div>
                    <div class="score-card">
                        <div>å®šä½å¾—åˆ†</div>
                        <div class="score-value">{profile.localization_score:.3f}</div>
                    </div>
                    <div class="score-card">
                        <div>å…‰å­æ•°å¾—åˆ†</div>
                        <div class="score-value">{profile.photon_score:.3f}</div>
                    </div>
                    <div class="score-card">
                        <div>æ•ˆç‡å¾—åˆ†</div>
                        <div class="score-value">{profile.efficiency_score:.3f}</div>
                    </div>
                    <div class="score-card">
                        <div>ç¨³å®šæ€§å¾—åˆ†</div>
                        <div class="score-value">{profile.stability_score:.3f}</div>
                    </div>
                </div>
            </div>
            
            <div class="section">
                <h2>æ€§èƒ½å¯è§†åŒ–</h2>
                <div class="chart">
                    <img src="performance_radar.png" alt="æ€§èƒ½é›·è¾¾å›¾" style="max-width: 100%; height: auto;">
                </div>
                <div class="chart">
                    <img src="performance_bars.png" alt="æ€§èƒ½æ¡å½¢å›¾" style="max-width: 100%; height: auto;">
                </div>
            </div>
            
            <div class="section">
                <h2>æ€§èƒ½ç“¶é¢ˆ</h2>
                {''.join([f'<div class="bottleneck">âš ï¸ {bottleneck}</div>' for bottleneck in profile.bottlenecks]) if profile.bottlenecks else '<p>æœªå‘ç°æ˜æ˜¾æ€§èƒ½ç“¶é¢ˆ</p>'}
            </div>
            
            <div class="section">
                <h2>ä¼˜åŒ–å»ºè®®</h2>
                {''.join([f'<div class="recommendation">ğŸ’¡ {rec}</div>' for rec in profile.recommendations])}
            </div>
            
            <div class="section">
                <h2>æ•°æ®é›†ä¿¡æ¯</h2>
                <table>
                    <tr><th>é¡¹ç›®</th><th>å€¼</th></tr>
                    <tr><td>æ•°æ®é›†åç§°</td><td>{profile.dataset_info['name']}</td></tr>
                    <tr><td>æ ·æœ¬æ•°é‡</td><td>{profile.dataset_info['num_samples']}</td></tr>
                    <tr><td>å¤„ç†æ—¶é—´</td><td>{profile.dataset_info['processing_time']:.2f} ç§’</td></tr>
                    <tr><td>å†…å­˜ä½¿ç”¨</td><td>{profile.dataset_info['memory_usage']:.2f} MB</td></tr>
                    <tr><td>å¹³å‡å¤„ç†é€Ÿåº¦</td><td>{profile.dataset_info['num_samples'] / max(profile.dataset_info['processing_time'], 0.001):.2f} æ ·æœ¬/ç§’</td></tr>
                </table>
            </div>
        </body>
        </html>
        """
        
        report_path = output_path / "performance_analysis_report.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return report_path